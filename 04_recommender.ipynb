{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ea1df9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ksquare/.pyenv/versions/3.11.10/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating datasets...\n",
      "  user_id                                            profile  \\\n",
      "0    u000  Radiation protection practitioner who enjoys s...   \n",
      "1    u001                    Town planner who enjoys college   \n",
      "2    u002                      Art therapist who enjoys land   \n",
      "3    u003               Recycling officer who enjoys usually   \n",
      "4    u004  Training and development officer who enjoys truth   \n",
      "5    u005                     Comptroller who enjoys already   \n",
      "6    u006           Clinical embryologist who enjoys western   \n",
      "7    u007  Armed forces training and education officer wh...   \n",
      "8    u008                         Dealer who enjoys election   \n",
      "9    u009             Occupational therapist who enjoys bill   \n",
      "\n",
      "                                             reviews       ratings  \n",
      "0  [Mr why myself still value investment finish f...  [1, 1, 3, 2]  \n",
      "1  [Between too one according challenge identify ...        [2, 1]  \n",
      "2  [Here become contain keep hard may direction c...  [5, 1, 5, 4]  \n",
      "3  [Task protect ask see hour key law., Majority ...        [1, 1]  \n",
      "4  [Fast understand third get crime herself move ...        [2, 5]  \n",
      "5  [Who serve or practice ready product., Rule ca...  [1, 5, 2, 5]  \n",
      "6  [Wall each relate age lose number change job c...     [2, 4, 5]  \n",
      "7  [Wear change through both bar nearly governmen...     [1, 2, 4]  \n",
      "8  [Bad memory opportunity decision Democrat numb...     [3, 2, 2]  \n",
      "9  [Car plan compare much reach girl him century ...     [1, 1, 4]  \n",
      "Loading embedding model...\n",
      "Recommending books...\n",
      "\n",
      "Sample Recommendations:\n",
      "User u000 → Books: ['b052', 'b024', 'b076']\n",
      "User u001 → Books: ['b087', 'b014', 'b005']\n",
      "User u002 → Books: ['b043', 'b024', 'b082']\n",
      "User u003 → Books: ['b024', 'b087', 'b091']\n",
      "User u004 → Books: ['b073', 'b079', 'b092']\n"
     ]
    }
   ],
   "source": [
    "from faker import Faker\n",
    "import random\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Initialize Faker and seeds\n",
    "faker = Faker()\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# ---------------------\n",
    "# 1. Generate Users\n",
    "# ---------------------\n",
    "def generate_users(num_users=50):\n",
    "    users = []\n",
    "    for i in range(num_users):\n",
    "        user_id = f\"u{i:03d}\"\n",
    "        profile = faker.job() + \" who enjoys \" + faker.word()\n",
    "        reviews = [faker.sentence(nb_words=10) for _ in range(random.randint(2, 4))]\n",
    "        ratings = [random.randint(1, 5) for _ in range(len(reviews))]\n",
    "        users.append({\n",
    "            \"user_id\": user_id,\n",
    "            \"profile\": profile,\n",
    "            \"reviews\": reviews,\n",
    "            \"ratings\": ratings\n",
    "        })\n",
    "    return pd.DataFrame(users)\n",
    "\n",
    "# ---------------------\n",
    "# 2. Generate Books\n",
    "# ---------------------\n",
    "def generate_books(num_books=100):\n",
    "    books = []\n",
    "    for i in range(num_books):\n",
    "        book_id = f\"b{i:03d}\"\n",
    "        title = faker.sentence(nb_words=4).rstrip('.')\n",
    "        description = faker.paragraph(nb_sentences=3)\n",
    "        books.append({\n",
    "            \"book_id\": book_id,\n",
    "            \"title\": title,\n",
    "            \"description\": description\n",
    "        })\n",
    "    return pd.DataFrame(books)\n",
    "\n",
    "# ---------------------\n",
    "# 3. Compute Embeddings\n",
    "# ---------------------\n",
    "def compute_embeddings(model, texts):\n",
    "    return model.encode(texts, convert_to_tensor=True)\n",
    "\n",
    "# ---------------------\n",
    "# 4. Recommend Books\n",
    "# ---------------------\n",
    "def recommend_books(user_df, book_df, model, top_k=3):\n",
    "    recommendations = {}\n",
    "\n",
    "    # Prepare book embeddings\n",
    "    book_texts = (book_df[\"title\"] + \" \" + book_df[\"description\"]).tolist()\n",
    "    book_embeddings = compute_embeddings(model, book_texts)\n",
    "    book_embeddings_cpu = book_embeddings.cpu().numpy()\n",
    "\n",
    "    for idx, user in user_df.iterrows():\n",
    "        # Combine profile and reviews\n",
    "        user_text = user[\"profile\"] + \" \" + \" \".join(user[\"reviews\"])\n",
    "        user_embedding = compute_embeddings(model, [user_text])[0].unsqueeze(0).cpu().numpy()\n",
    "\n",
    "        # Compute cosine similarity\n",
    "        similarities = cosine_similarity(user_embedding, book_embeddings_cpu)[0]\n",
    "\n",
    "        # Recommend top-k (ignoring previously reviewed books)\n",
    "        top_indices = np.argsort(similarities)[::-1]\n",
    "        recommendations[user[\"user_id\"]] = [\n",
    "            book_df.iloc[i][\"book_id\"]\n",
    "            for i in top_indices[:top_k]\n",
    "        ]\n",
    "\n",
    "    return recommendations\n",
    "\n",
    "\n",
    "# ---------------------\n",
    "# 5. Full Run\n",
    "# ---------------------\n",
    "def main():\n",
    "    print(\"Generating datasets...\")\n",
    "    users = generate_users()\n",
    "    print(users.head(10))\n",
    "\n",
    "    books = generate_books()\n",
    "    users.to_csv(\"users.csv\", index=False)\n",
    "    books.to_csv(\"books.csv\", index=False)\n",
    "\n",
    "    print(\"Loading embedding model...\")\n",
    "    model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "    print(\"Recommending books...\")\n",
    "    recs = recommend_books(users, books, model)\n",
    "\n",
    "    print(\"\\nSample Recommendations:\")\n",
    "    for user_id, book_ids in list(recs.items())[:5]:\n",
    "        print(f\"User {user_id} → Books: {book_ids}\")\n",
    "\n",
    "    return users, books, recs\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    users_df, books_df, recommendations = main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039138e8",
   "metadata": {},
   "source": [
    "# exam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1626b476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating synthetic datasets...\n",
      "Loading sentence embedding model...\n",
      "Generating recommendations...\n",
      "\n",
      "Sample output:\n",
      "User u000 → Recommended Books: ['b096', 'b034', 'b015']\n",
      "User u001 → Recommended Books: ['b028', 'b053', 'b044']\n",
      "User u002 → Recommended Books: ['b096', 'b028', 'b070']\n",
      "User u003 → Recommended Books: ['b050', 'b042', 'b038']\n",
      "User u004 → Recommended Books: ['b099', 'b051', 'b047']\n"
     ]
    }
   ],
   "source": [
    "# Book Recommender - Student Version\n",
    "# Final Project — Embeddings and Semantic Understanding\n",
    "\n",
    "from faker import Faker\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "# Optional: from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# === NOTES FOR ALL PLATFORMS ===\n",
    "# - If you are on Windows, make sure you install dependencies with:\n",
    "#     pip install pandas faker sentence-transformers scikit-learn\n",
    "#\n",
    "# - If you're on Mac and using Apple Silicon (M1/M2/M3), you may face issues\n",
    "#   if your model runs on 'mps' (Metal Performance Shaders).\n",
    "#   This can break compatibility with sklearn. If that happens, use .cpu().numpy()\n",
    "#   or just force the model to run on CPU by:\n",
    "#       import torch; torch.device(\"cpu\")\n",
    "#   and avoid `.to(\"mps\")` or `.to(\"cuda\")`.\n",
    "\n",
    "# ---------------------\n",
    "# STEP 1. Generate Users\n",
    "# ---------------------\n",
    "\n",
    "def generate_users(num_users=50):\n",
    "    faker = Faker()\n",
    "    random.seed(42)\n",
    "    users = []\n",
    "    for i in range(num_users):\n",
    "        user_id = f\"u{i:03d}\"\n",
    "        profile = faker.job() + \" who enjoys \" + faker.word()\n",
    "        reviews = [faker.sentence(nb_words=10) for _ in range(random.randint(2, 4))]\n",
    "        ratings = [random.randint(1, 5) for _ in range(len(reviews))]\n",
    "        users.append({\n",
    "            \"user_id\": user_id,\n",
    "            \"profile\": profile,\n",
    "            \"reviews\": reviews,\n",
    "            \"ratings\": ratings\n",
    "        })\n",
    "    return pd.DataFrame(users)\n",
    "\n",
    "# ---------------------\n",
    "# STEP 2. Generate Books\n",
    "# ---------------------\n",
    "\n",
    "def generate_books(num_books=100):\n",
    "    faker = Faker()\n",
    "    books = []\n",
    "    for i in range(num_books):\n",
    "        book_id = f\"b{i:03d}\"\n",
    "        title = faker.sentence(nb_words=4).rstrip('.')\n",
    "        description = faker.paragraph(nb_sentences=3)\n",
    "        books.append({\n",
    "            \"book_id\": book_id,\n",
    "            \"title\": title,\n",
    "            \"description\": description\n",
    "        })\n",
    "    return pd.DataFrame(books)\n",
    "\n",
    "# ---------------------\n",
    "# STEP 3. Save Data to CSV (Optional for viewing)\n",
    "# ---------------------\n",
    "\n",
    "def save_datasets(users, books):\n",
    "    users.to_csv(\"users.csv\", index=False)\n",
    "    books.to_csv(\"books.csv\", index=False)\n",
    "\n",
    "# ---------------------\n",
    "# STEP 4. Recommender Logic (TO COMPLETE)\n",
    "# ---------------------\n",
    "\n",
    "def recommend_books(user_df, book_df, model, top_k=3):\n",
    "      from sklearn.metrics.pairwise import cosine_similarity\n",
    "      import torch\n",
    "\n",
    "      recommendations = {}\n",
    "\n",
    "      # Prepare book input text: title + description\n",
    "      book_texts = (book_df[\"title\"] + \" \" + book_df[\"description\"]).tolist()\n",
    "\n",
    "      # Get book embeddings and convert to numpy for sklearn compatibility\n",
    "      book_embeddings = model.encode(book_texts, convert_to_tensor=True)\n",
    "      book_embeddings = book_embeddings.cpu().numpy()\n",
    "\n",
    "      for idx, user in user_df.iterrows():\n",
    "          # Combine user's profile and reviews\n",
    "          user_text = user[\"profile\"] + \" \" + \" \".join(user[\"reviews\"])\n",
    "\n",
    "          # Get user embedding and convert to numpy\n",
    "          user_embedding = model.encode([user_text], convert_to_tensor=True)\n",
    "          user_embedding = user_embedding.cpu().numpy()\n",
    "\n",
    "          # Calculate cosine similarity between user and all books\n",
    "          similarities = cosine_similarity(user_embedding, book_embeddings)[0]\n",
    "\n",
    "          # Get indices of top_k most similar books\n",
    "          top_indices = similarities.argsort()[-top_k:][::-1]\n",
    "\n",
    "          # Get the book IDs for recommendations\n",
    "          recommended_book_ids = [book_df.iloc[i][\"book_id\"] for i in\n",
    "  top_indices]\n",
    "\n",
    "          recommendations[user[\"user_id\"]] = recommended_book_ids\n",
    "\n",
    "      return recommendations\n",
    "\n",
    "# ---------------------\n",
    "# STEP 5. Main Run\n",
    "# ---------------------\n",
    "\n",
    "def main():\n",
    "    print(\"Generating synthetic datasets...\")\n",
    "    users = generate_users()\n",
    "    books = generate_books()\n",
    "    save_datasets(users, books)\n",
    "\n",
    "    print(\"Loading sentence embedding model...\")\n",
    "    model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "    print(\"Generating recommendations...\\n\")\n",
    "    recommendations = recommend_books(users, books, model)\n",
    "\n",
    "    print(\"Sample output:\")\n",
    "    for user_id, book_ids in list(recommendations.items())[:5]:\n",
    "        print(f\"User {user_id} → Recommended Books: {book_ids}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d3ddaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
